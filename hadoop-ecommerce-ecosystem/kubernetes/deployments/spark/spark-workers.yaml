apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: spark-worker
  namespace: hadoop-ecosystem
  labels:
    app: spark
    component: worker
spec:
  serviceName: spark-worker
  replicas: 2
  selector:
    matchLabels:
      app: spark
      component: worker
  template:
    metadata:
      labels:
        app: spark
        component: worker
    spec:
      containers:
      - name: spark-worker
        image: spark:3.4.1
        imagePullPolicy: Always
        command: ["/scripts/start-worker.sh", "spark://spark-master:7077"]
        ports:
        - containerPort: 8081
          name: webui-port
        - containerPort: 7078
          name: worker-port
        env:
        - name: SPARK_MODE
          value: "worker"
        - name: SPARK_MASTER_URL
          value: "spark://spark-master:7077"
        - name: SPARK_WORKER_CORES
          value: "2"
        - name: SPARK_WORKER_MEMORY
          value: "3g"
        - name: SPARK_WORKER_PORT
          value: "7078"
        - name: SPARK_WORKER_WEBUI_PORT
          value: "8081"
        - name: JAVA_HOME
          value: "/usr/local/openjdk-8"
        resources:
          requests:
            memory: "2Gi"
            cpu: "1"
          limits:
            memory: "4Gi"
            cpu: "2"
        volumeMounts:
        - name: spark-config
          mountPath: /opt/spark/conf
        - name: spark-scripts
          mountPath: /scripts
        - name: spark-work
          mountPath: /opt/spark/work
        - name: spark-logs
          mountPath: /opt/spark/logs
        readinessProbe:
          httpGet:
            path: /
            port: 8081
          initialDelaySeconds: 30
          periodSeconds: 10
        livenessProbe:
          httpGet:
            path: /
            port: 8081
          initialDelaySeconds: 60
          periodSeconds: 30
      volumes:
      - name: spark-config
        configMap:
          name: spark-config
      - name: spark-scripts
        configMap:
          name: spark-scripts
          defaultMode: 0755
      - name: spark-work
        emptyDir: {}
      - name: spark-logs
        emptyDir: {}
      nodeSelector:
        node-role: worker