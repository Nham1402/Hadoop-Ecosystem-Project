apiVersion: v1
kind: ConfigMap
metadata:
  name: spark-config
  namespace: hadoop-ecosystem
  labels:
    app: spark
data:
  spark-defaults.conf: |
    spark.master                     spark://spark-master:7077
    spark.eventLog.enabled           true
    spark.eventLog.dir               hdfs://hadoop-namenode:8020/spark-logs
    spark.history.fs.logDirectory    hdfs://hadoop-namenode:8020/spark-logs
    spark.serializer                 org.apache.spark.serializer.KryoSerializer
    spark.executor.memory            2g
    spark.executor.cores             2
    spark.driver.memory              1g
    spark.driver.cores               1
    spark.executor.instances         2
    spark.dynamicAllocation.enabled  true
    spark.dynamicAllocation.minExecutors    1
    spark.dynamicAllocation.maxExecutors    4
    spark.shuffle.service.enabled    true
    spark.sql.adaptive.enabled       true
    spark.hadoop.fs.defaultFS        hdfs://hadoop-namenode:8020
    spark.sql.warehouse.dir          hdfs://hadoop-namenode:8020/spark-warehouse
    spark.driver.host                0.0.0.0
    spark.driver.bindAddress         0.0.0.0
    spark.ui.enabled                 true
    spark.ui.port                    4040
    spark.io.compression.codec       snappy
    spark.rdd.compress               true
    spark.executor.extraJavaOptions  -XX:+UseG1GC -XX:+UseStringDeduplication
    spark.driver.extraJavaOptions    -XX:+UseG1GC -XX:+UseStringDeduplication
    spark.kubernetes.namespace       hadoop-ecosystem
    spark.kubernetes.authenticate.driver.serviceAccountName  spark

  spark-env.sh: |
    #!/usr/bin/env bash
    export JAVA_HOME=/usr/local/openjdk-8
    export SPARK_HOME=/opt/spark
    export PYSPARK_PYTHON=python3
    export PYSPARK_DRIVER_PYTHON=python3
    export SPARK_MASTER_HOST=0.0.0.0
    export SPARK_MASTER_PORT=7077
    export SPARK_MASTER_WEBUI_PORT=8080
    export SPARK_WORKER_CORES=2
    export SPARK_WORKER_MEMORY=3g
    export SPARK_WORKER_PORT=7078
    export SPARK_WORKER_WEBUI_PORT=8081
    export SPARK_DAEMON_MEMORY=1g
    export SPARK_LOG_DIR=/opt/spark/logs
    export SPARK_PID_DIR=/tmp
    export SPARK_DRIVER_MEMORY=1g
    export SPARK_EXECUTOR_MEMORY=2g

  log4j.properties: |
    log4j.rootCategory=INFO, console
    log4j.appender.console=org.apache.log4j.ConsoleAppender
    log4j.appender.console.target=System.err
    log4j.appender.console.layout=org.apache.log4j.PatternLayout
    log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n
    log4j.logger.org.apache.spark.repl.Main=WARN
    log4j.logger.org.spark_project.jetty=WARN
    log4j.logger.org.spark_project.jetty.util.component.AbstractLifeCycle=ERROR
    log4j.logger.org.apache.parquet=ERROR
    log4j.logger.parquet=ERROR
    log4j.logger.org.apache.hadoop.hive.metastore.RetryingHMSHandler=FATAL
    log4j.logger.org.apache.hadoop.hive.ql.exec.FunctionRegistry=ERROR