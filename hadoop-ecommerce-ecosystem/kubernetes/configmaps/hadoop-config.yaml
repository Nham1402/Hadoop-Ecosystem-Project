apiVersion: v1
kind: ConfigMap
metadata:
  name: hadoop-config
  namespace: hadoop-ecosystem
  labels:
    app: hadoop
data:
  core-site.xml: |
    <?xml version="1.0" encoding="UTF-8"?>
    <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
    <configuration>
        <property>
            <name>fs.defaultFS</name>
            <value>hdfs://hadoop-namenode:8020</value>
        </property>
        <property>
            <name>hadoop.tmp.dir</name>
            <value>/hadoop/tmp</value>
        </property>
        <property>
            <name>hadoop.proxyuser.root.hosts</name>
            <value>*</value>
        </property>
        <property>
            <name>hadoop.proxyuser.root.groups</name>
            <value>*</value>
        </property>
        <property>
            <name>io.compression.codecs</name>
            <value>org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.BZip2Codec,org.apache.hadoop.io.compress.SnappyCodec</value>
        </property>
        <property>
            <name>hadoop.security.authentication</name>
            <value>simple</value>
        </property>
    </configuration>

  hdfs-site.xml: |
    <?xml version="1.0" encoding="UTF-8"?>
    <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
    <configuration>
        <property>
            <name>dfs.namenode.name.dir</name>
            <value>file:///hadoop/dfs/name</value>
        </property>
        <property>
            <name>dfs.namenode.http-address</name>
            <value>0.0.0.0:9870</value>
        </property>
        <property>
            <name>dfs.namenode.rpc-address</name>
            <value>hadoop-namenode:8020</value>
        </property>
        <property>
            <name>dfs.datanode.data.dir</name>
            <value>file:///hadoop/dfs/data</value>
        </property>
        <property>
            <name>dfs.datanode.http.address</name>
            <value>0.0.0.0:9864</value>
        </property>
        <property>
            <name>dfs.replication</name>
            <value>2</value>
        </property>
        <property>
            <name>dfs.blocksize</name>
            <value>134217728</value>
        </property>
        <property>
            <name>dfs.permissions.enabled</name>
            <value>false</value>
        </property>
        <property>
            <name>dfs.webhdfs.enabled</name>
            <value>true</value>
        </property>
    </configuration>

  yarn-site.xml: |
    <?xml version="1.0"?>
    <configuration>
        <property>
            <name>yarn.resourcemanager.hostname</name>
            <value>yarn-resourcemanager</value>
        </property>
        <property>
            <name>yarn.resourcemanager.address</name>
            <value>yarn-resourcemanager:8032</value>
        </property>
        <property>
            <name>yarn.resourcemanager.webapp.address</name>
            <value>yarn-resourcemanager:8088</value>
        </property>
        <property>
            <name>yarn.nodemanager.aux-services</name>
            <value>mapreduce_shuffle</value>
        </property>
        <property>
            <name>yarn.nodemanager.resource.memory-mb</name>
            <value>3072</value>
        </property>
        <property>
            <name>yarn.nodemanager.resource.cpu-vcores</name>
            <value>2</value>
        </property>
        <property>
            <name>yarn.scheduler.maximum-allocation-mb</name>
            <value>3072</value>
        </property>
        <property>
            <name>yarn.scheduler.minimum-allocation-mb</name>
            <value>256</value>
        </property>
        <property>
            <name>yarn.log-aggregation-enable</name>
            <value>true</value>
        </property>
        <property>
            <name>yarn.nodemanager.vmem-check-enabled</name>
            <value>false</value>
        </property>
    </configuration>

  mapred-site.xml: |
    <?xml version="1.0"?>
    <configuration>
        <property>
            <name>mapreduce.framework.name</name>
            <value>yarn</value>
        </property>
        <property>
            <name>mapreduce.map.memory.mb</name>
            <value>1024</value>
        </property>
        <property>
            <name>mapreduce.map.java.opts</name>
            <value>-Xmx768m</value>
        </property>
        <property>
            <name>mapreduce.reduce.memory.mb</name>
            <value>1024</value>
        </property>
        <property>
            <name>mapreduce.reduce.java.opts</name>
            <value>-Xmx768m</value>
        </property>
        <property>
            <name>mapreduce.output.fileoutputformat.compress</name>
            <value>true</value>
        </property>
        <property>
            <name>mapreduce.output.fileoutputformat.compress.codec</name>
            <value>org.apache.hadoop.io.compress.SnappyCodec</value>
        </property>
    </configuration>

  hadoop-env.sh: |
    #!/bin/bash
    export JAVA_HOME=/usr/local/openjdk-8
    export HADOOP_HOME=/opt/hadoop
    export HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
    export HADOOP_HEAPSIZE=1000
    export HADOOP_OPTS="$HADOOP_OPTS -Djava.net.preferIPv4Stack=true"
    export HADOOP_NAMENODE_OPTS="-Xmx2g -XX:+UseG1GC $HADOOP_NAMENODE_OPTS"
    export HADOOP_DATANODE_OPTS="-Xmx1g -XX:+UseG1GC $HADOOP_DATANODE_OPTS"
    export YARN_RESOURCEMANAGER_OPTS="-Xmx2g -XX:+UseG1GC $YARN_RESOURCEMANAGER_OPTS"
    export YARN_NODEMANAGER_OPTS="-Xmx1g -XX:+UseG1GC $YARN_NODEMANAGER_OPTS"